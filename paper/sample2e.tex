\documentclass[letterpaper]{article}
\usepackage{proceed2e}
\usepackage[margin=1in]{geometry}
\usepackage{mathtools}
\usepackage{amsfonts}

\usepackage{times}

\newtheorem{theorem}{Theorem}

\title{Bayesian LISTA / Uncertainty propagation in deep neural networks for sparse coding}

\author{} % LEAVE BLANK FOR ORIGINAL SUBMISSION.
          % UAI  reviewing is double-blind.

% The author names and affiliations should appear only in the accepted paper.
%
%\author{ {\bf Harry Q.~Bovik\thanks{Footnote for author to give an
%alternate address.}} \\
%Computer Science Dept. \\
%Cranberry University\\
%Pittsburgh, PA 15213 \\
%\And
%{\bf Coauthor}  \\
%Affiliation          \\
%Address \\
%\And
%{\bf Coauthor}   \\
%Affiliation \\
%Address    \\
%(if needed)\\
%}

\begin{document}

\maketitle

\begin{abstract}
We propose the method of propagating the uncertainty through the multilevel soft-thresholding nonlinearity. This allows to use it as a building block for sparse coding deep neural networks. As an example we develop the Bayesian LISTA algorithm. It allows to obtain the variance estimates for parameters and posterior distributions.
\end{abstract}

\section{Uncertainty propagation through LISTA-like neural network with separated layers}

NN scheme:

\begin{align}
&b = W_0y\\
&\widehat{\beta}_0 = h_\lambda(b) \\
&\text{for } l=1:L\\
	&\quad b_l = W_l y \\
	&\quad c_l = b_l + S_l\widehat{\beta}_{l-1} \\
	&\quad \widehat{\beta}_{l} = h_\lambda(c_l) \\
& \widehat{\beta} = \widehat{\beta}_{L}
\end{align}

 \begin{theorem}
 Let $W \in \mathbb{R}^{D \times K}$ be a matrix of Gaussian-distributed random variables: $W_{dk} \sim \mathcal{N}(m^w_{dk}, v^w_{dk})$, and $y \in \mathbb{R}^K$ be a constant vector. Their multiplication is a vector $b \in \mathbb{R}^{D}$ of random variables $b_d \sim \mathcal{N}(\sum_{k=1}^Ky_km^w_{dk}, \sum_{k=1}^Ky_k^2v^w_{dk})$.
 \end{theorem}

\end{document}
